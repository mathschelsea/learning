{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast.ai Machine Learning - Course 1, Lesson 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pandas.api.types import is_string_dtype, is_object_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change current working directory\n",
    "os.chdir('..')\n",
    "print(f'cwd: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Downloading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section only needs to be run once.\n",
    "\n",
    "Downloading data from Kaggle requires us to:\n",
    "1. Install Kaggle\n",
    "2. Create a Kaggle folder in our home directory (it'll be hidden)\n",
    "3. Get our API credentials from the Kaggle 'Settings' page\n",
    "4. Place the credentials (.json file) in the Kaggle folder from step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a kaggle directory\n",
    "dir = os.path.expanduser('~/.kaggle')\n",
    "os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy credentials to kaggle folder\n",
    "creds = '/Users/chelseatucker/credentials/kaggle.json'\n",
    "!cp $creds ~/.kaggle\n",
    "\n",
    "# change permissions so only I have read & write access to the credentials file\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bulldozers directory\n",
    "os.makedirs('data/bbfb', exist_ok=True)\n",
    "\n",
    "# downloading the bulldozers dataset to the 'data' folder\n",
    "!kaggle competitions download -c bluebook-for-bulldozers -p 'data/bbfb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unzip the data\n",
    "!unzip -q data/bbfb/bluebook-for-bulldozers.zip -d 'data/bbfb'\n",
    "\n",
    "# unzip train data\n",
    "!unzip -q data/bbfb/Train.zip -d 'data/bbfb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('data/bbfb/Train.csv', \n",
    "                     low_memory=False, \n",
    "                     parse_dates=['saledate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# quick look to see if the data has imported correctly\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eda import df_look\n",
    "\n",
    "# high level overview of the data\n",
    "df_look(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Data Edits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competiton wants us to use RMSLE as the measure between actuals and predictions so we'll take the log of the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.SalePrice = np.log(df_raw.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual edits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at individual levels\n",
    "df_raw.Blade_Width.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column to string\n",
    "df_raw.Blade_Width = df_raw.Blade_Width.astype('string', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.x - Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting more information from date/time columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import add_dateattr\n",
    "\n",
    "# extracting more information from the date field\n",
    "add_dateattr(df_raw, 'saledate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.x - Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list object/string columns\n",
    "cats = []\n",
    "for c in df_raw.columns:\n",
    "    if is_string_dtype(df_raw[c]) or is_object_dtype(df_raw[c]): \n",
    "        cats.append(c)\n",
    "\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import conv_to_cat\n",
    "\n",
    "# converting all string/object columns to categories\n",
    "conv_to_cat(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking category orders\n",
    "for c in cats:\n",
    "    print(c,':',df_raw[c].cat.categories)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering categories\n",
    "df_raw.UsageBand = df_raw.UsageBand.cat.reorder_categories(['Low', 'Medium', 'High'], ordered=True)\n",
    "df_raw.ProductSize = df_raw.ProductSize.cat.reorder_categories(['Mini', 'Small', 'Compact', 'Medium', 'Large / Medium', 'Large'], ordered=True)\n",
    "df_raw.Blade_Width = df_raw.Blade_Width.cat.reorder_categories([\"<12'\", \"12'\", \"13'\", \"14'\", \"16'\", \"None or Unspecified\"], ordered=True)\n",
    "df_raw.Tire_Size = df_raw.Tire_Size.reorder_categories(['Low', 'Medium', 'High'], ordered=True)\n",
    "\n",
    "# checking after reordering\n",
    "df_raw.UsageBand.cat.categories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
